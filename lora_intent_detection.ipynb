{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNK5OwzbxQfknv67GqUtOg/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agataskrzyniarz1/chatbot-intent-detection-lora-finetuning/blob/main/lora_intent_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "914PwJgFMve7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, pipeline, EarlyStoppingCallback\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from huggingface_hub import login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KI_Pz7qOEBkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the dataset"
      ],
      "metadata": {
        "id": "csgTmuq2UleY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"tanaos/synthetic-intent-classifier-dataset-v1\")"
      ],
      "metadata": {
        "id": "AW47CXhIP9GR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "id": "O-uNERJYP9D_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split1 = dataset['train'].train_test_split(test_size=0.2, seed=42)  # 80/20\n",
        "split2 = split1['test'].train_test_split(test_size=0.5, seed=42)     # 10/10\n",
        "\n",
        "datasets_final = DatasetDict({\n",
        "    'train': split1['train'],\n",
        "    'validation': split2['train'],\n",
        "    'test': split2['test']\n",
        "})\n",
        "\n",
        "print(datasets_final)"
      ],
      "metadata": {
        "id": "nzDdxaJNRD1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][:10]"
      ],
      "metadata": {
        "id": "3M_syW5pSZrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets_final[\"train\"].features[\"labels\"]"
      ],
      "metadata": {
        "id": "ZMz60s958hHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label categories\n",
        "\n",
        "id2label = {\n",
        "    0: \"greeting\",\n",
        "    1: \"farewell\",\n",
        "    2: \"thank_you\",\n",
        "    3: \"affirmation\",\n",
        "    4: \"negation\",\n",
        "    5: \"small_talk\",\n",
        "    6: \"bot_capabilities\",\n",
        "    7: \"feedback_positive\",\n",
        "    8: \"feedback_negative\",\n",
        "    9: \"clarification\",\n",
        "    10: \"suggestion\",\n",
        "    11: \"language_change\"\n",
        "}\n",
        "\n",
        "label2id = {v: k for k, v in id2label.items()}\n"
      ],
      "metadata": {
        "id": "iWWvaDPr9h5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the base model"
      ],
      "metadata": {
        "id": "FZILo0YbUr9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "num_labels=12\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=12,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id # adding label categories\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "Mb70dP59P9BY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check\n",
        "i = 0\n",
        "ex = datasets_final[\"train\"][i]\n",
        "\n",
        "print(\"TEXT:\", ex[\"text\"])\n",
        "print(\"LABEL ID:\", ex[\"labels\"])\n",
        "print(\"LABEL NAME:\", id2label[ex[\"labels\"]])"
      ],
      "metadata": {
        "id": "GyMUT9ma-dlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "s9gx2iErU0Hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "tokenized_datasets = datasets_final.map(\n",
        "    preprocess_function, batched=True, remove_columns=['text']\n",
        ")\n"
      ],
      "metadata": {
        "id": "6oF-Lij0P8_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets"
      ],
      "metadata": {
        "id": "MX0FmkMc00ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check\n",
        "i = 0\n",
        "example = tokenized_datasets[\"train\"][i]\n",
        "print(example)\n"
      ],
      "metadata": {
        "id": "DCaVFn4F02Jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LoRA configuration"
      ],
      "metadata": {
        "id": "ix8wWlo_1gSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,  # sequence classification\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()\n"
      ],
      "metadata": {
        "id": "QBlXouY_P88W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training arguments"
      ],
      "metadata": {
        "id": "Vd4qYjEvU_lQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./checkpoints/intent-lora\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-4,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=8,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    logging_steps=50,\n",
        "    save_total_limit=2,\n",
        "    report_to=\"none\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "UDOcnW7EP850"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {\"accuracy\": accuracy_score(labels, predictions)}\n"
      ],
      "metadata": {
        "id": "XcAjT-XKP81D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data collator and trainer"
      ],
      "metadata": {
        "id": "3BkQxym8VFBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JRbT2q-QP8m7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "aVZW9ZO3VJUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "\n",
        "trainer.save_model(\"./best_model/intent-lora\")\n",
        "tokenizer.save_pretrained(\"./best_model/intent-lora\")\n"
      ],
      "metadata": {
        "id": "Uxcnd3OOWa0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model on drive\n",
        "#!cp -r ./best_model/intent-lora /content/drive/MyDrive/intent_detection_fine_tuning/"
      ],
      "metadata": {
        "id": "jqgVlX14CrLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quick evaluation"
      ],
      "metadata": {
        "id": "eqU9RRglVSf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "text = \"do you speak chinese?\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    pred_id = torch.argmax(outputs.logits, dim=-1).item()\n",
        "\n",
        "pred_label = id2label[pred_id]\n",
        "\n",
        "print(\"Predicted label:\", pred_label)\n"
      ],
      "metadata": {
        "id": "Hw1bx37XWawF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test set evaluation"
      ],
      "metadata": {
        "id": "u2bM4r25UcQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# categories\n",
        "label_names = [\n",
        "    \"greeting\",\n",
        "    \"farewell\",\n",
        "    \"thank_you\",\n",
        "    \"affirmation\",\n",
        "    \"negation\",\n",
        "    \"small_talk\",\n",
        "    \"bot_capabilities\",\n",
        "    \"feedback_positive\",\n",
        "    \"feedback_negative\",\n",
        "    \"clarification\",\n",
        "    \"suggestion\",\n",
        "    \"language_change\"\n",
        "]\n",
        "\n",
        "# test set predictions\n",
        "preds_output = trainer.predict(tokenized_datasets['test'])\n",
        "\n",
        "y_pred = np.argmax(preds_output.predictions, axis=1)\n",
        "y_true = preds_output.label_ids\n",
        "\n",
        "# classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=label_names))\n",
        "\n",
        "# confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=label_names, yticklabels=label_names, cmap=\"Blues\")\n",
        "plt.ylabel(\"True label\")\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Te2knXBHWasS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Push to Huggingface Hub"
      ],
      "metadata": {
        "id": "pBi5SB9vQMPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "login()"
      ],
      "metadata": {
        "id": "1OM7gtwbWapa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge the base model with the LoRA adapter"
      ],
      "metadata": {
        "id": "qWNPpDUhTrwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the base model\n",
        "model_base = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=12,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ").to(device)\n",
        "\n",
        "# load the adapter\n",
        "adapter = PeftModel.from_pretrained(model_base, \"./best_model/intent-lora\")\n",
        "\n",
        "# merge base model and adapter\n",
        "model_merged = adapter.merge_and_unload()"
      ],
      "metadata": {
        "id": "o1ZPH7YsWagO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#push to hub\n",
        "model_merged.push_to_hub(\"agataskrzyniarz/intent-detection-chatbot\", use_auth_token=True)\n",
        "tokenizer.push_to_hub(\"agataskrzyniarz/intent-detection-chatbot\")"
      ],
      "metadata": {
        "id": "qMvAsYfROMWc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}